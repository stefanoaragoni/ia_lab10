{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 10 - Clasificación de Perros y Gatos\n",
    "\n",
    "Stefano Aragoni, Carol Arévalo, Luis Diego Santos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar Librerías\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-03 16:14:08.150196: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.1.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import cv2\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from skimage import color, filters, measure"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Lectura del Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lectura y Procesamiento de Imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_image_corrupted(file_path):\n",
    "    try:\n",
    "        with Image.open(file_path) as img:\n",
    "            img.verify()\n",
    "        return False\n",
    "    except:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(path, size=(150, 150)):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    dirs = [\"Cat\", \"Dog\"]\n",
    "\n",
    "    for dir in dirs:\n",
    "        elements = os.listdir(path+'/'+dir)\n",
    "        random.shuffle(elements)\n",
    "\n",
    "        contador = 0\n",
    "\n",
    "        for file in elements:\n",
    "            if file.endswith('.jpg'):\n",
    "                img_path = os.path.join(path+'/'+dir, file)\n",
    "                label = 1 if 'Dog' == dir else 0\n",
    "\n",
    "                corrupta = is_image_corrupted(img_path)\n",
    "\n",
    "                if corrupta:\n",
    "                    continue\n",
    "\n",
    "                # Leer imagen a color\n",
    "                img = cv2.imread(img_path)\n",
    "\n",
    "                try:\n",
    "                    # Redimensionar imagen\n",
    "                    img = cv2.resize(img, size)\n",
    "\n",
    "                    # Convertir imagen a escala de grises\n",
    "                    gray_img = color.rgb2gray(img)\n",
    "\n",
    "                    # Aplicar umbral adaptativo para binarizar imagen\n",
    "                    binary_img = gray_img > filters.threshold_local(gray_img, block_size=35)\n",
    "\n",
    "                    # Label the objects in the binary image\n",
    "                    labeled_img = measure.label(binary_img)\n",
    "\n",
    "                    # Find the properties of the labeled objects\n",
    "                    properties = measure.regionprops(labeled_img)\n",
    "\n",
    "                    # Find the object with the largest area\n",
    "                    max_area = 0\n",
    "                    max_area_index = 0\n",
    "                    for i, prop in enumerate(properties):\n",
    "                        if prop.area > max_area:\n",
    "                            max_area = prop.area\n",
    "                            max_area_index = i\n",
    "\n",
    "                    # Extract the coordinates of the bounding box of the object\n",
    "                    min_row, min_col, max_row, max_col = properties[max_area_index].bbox\n",
    "\n",
    "                    # Crop the image to the bounding box of the object\n",
    "                    img = img[min_row:max_row, min_col:max_col]\n",
    "\n",
    "                    # expand the image to 150x150\n",
    "                    img = cv2.resize(img, size)\n",
    "\n",
    "                    # Girar imagen aleatoriamente\n",
    "                    if random.random() < 0.5:\n",
    "                        opt = random.randint(0, 3)\n",
    "\n",
    "                        if opt == 0:\n",
    "                            img = cv2.flip(img, 1)\n",
    "\n",
    "                        elif opt == 1:\n",
    "                            img = cv2.rotate(img, cv2.ROTATE_180)\n",
    "\n",
    "                        elif opt == 2:\n",
    "                            img = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
    "\n",
    "                        elif opt == 3:\n",
    "                            img = cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "\n",
    "\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                    \n",
    "                    # Normalizar valores de píxeles\n",
    "                    img = img / 255.0\n",
    "\n",
    "                    # # show image on popup\n",
    "                    # cv2.imshow('image', img)\n",
    "                    # cv2.waitKey(0)\n",
    "                    # cv2.destroyAllWindows()\n",
    "\n",
    "                    images.append(img)\n",
    "                    labels.append(label)\n",
    "                            \n",
    "                    if contador == 1300:\n",
    "                        break\n",
    "\n",
    "                    if contador % 100 == 0:\n",
    "                        print(\"Imagenes procesadas: \", contador)  \n",
    "\n",
    "                    contador += 1\n",
    "\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar Imagenes y Split de Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagenes procesadas:  0\n",
      "Imagenes procesadas:  100\n",
      "Imagenes procesadas:  200\n",
      "Imagenes procesadas:  300\n",
      "Imagenes procesadas:  400\n",
      "Imagenes procesadas:  500\n",
      "Imagenes procesadas:  600\n",
      "Imagenes procesadas:  700\n",
      "Imagenes procesadas:  800\n",
      "Imagenes procesadas:  900\n",
      "Imagenes procesadas:  1000\n",
      "Imagenes procesadas:  1100\n",
      "Imagenes procesadas:  1200\n",
      "Imagenes procesadas:  0\n",
      "Imagenes procesadas:  100\n",
      "Imagenes procesadas:  200\n",
      "Imagenes procesadas:  300\n",
      "Imagenes procesadas:  400\n",
      "Imagenes procesadas:  500\n",
      "Imagenes procesadas:  600\n",
      "Imagenes procesadas:  700\n",
      "Imagenes procesadas:  800\n",
      "Imagenes procesadas:  900\n",
      "Imagenes procesadas:  1000\n",
      "Imagenes procesadas:  1100\n",
      "Imagenes procesadas:  1200\n",
      "\n",
      "Número de imágenes por clase: [1301 1301]\n"
     ]
    }
   ],
   "source": [
    "# Definir ruta del conjunto de datos\n",
    "data_path = './PetImages'\n",
    "\n",
    "# Cargar imágenes y etiquetas\n",
    "images, labels = load_images(data_path)\n",
    "\n",
    "# Comprobar tamaños de los conjuntos\n",
    "print('\\nNúmero de imágenes por clase:', np.bincount(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tamaño del conjunto de entrenamiento: (2081, 150, 150)\n",
      "Tamaño del conjunto de validación: (261, 150, 150)\n",
      "Tamaño del conjunto de prueba: (260, 150, 150)\n"
     ]
    }
   ],
   "source": [
    "# Dividir conjunto de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Dividir 20 de prueba en 10 de validación y 10 de prueba\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "# Verificar tamaños de los conjuntos\n",
    "print('\\nTamaño del conjunto de entrenamiento:', X_train.shape)\n",
    "print('Tamaño del conjunto de validación:', X_val.shape)\n",
    "print('Tamaño del conjunto de prueba:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train, 2)\n",
    "y_val = to_categorical(y_val, 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Construccion del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "66/66 [==============================] - 59s 847ms/step - loss: 1.2153 - accuracy: 0.5435 - val_loss: 1.7346 - val_accuracy: 0.5172\n",
      "Epoch 2/20\n",
      "66/66 [==============================] - 55s 833ms/step - loss: 0.8630 - accuracy: 0.5805 - val_loss: 0.7236 - val_accuracy: 0.4943\n",
      "Epoch 3/20\n",
      "66/66 [==============================] - 51s 764ms/step - loss: 0.7625 - accuracy: 0.6358 - val_loss: 0.7903 - val_accuracy: 0.5019\n",
      "Epoch 4/20\n",
      "66/66 [==============================] - 50s 752ms/step - loss: 0.6828 - accuracy: 0.6564 - val_loss: 0.6948 - val_accuracy: 0.5134\n",
      "Epoch 5/20\n",
      "66/66 [==============================] - 51s 765ms/step - loss: 0.6479 - accuracy: 0.6756 - val_loss: 0.8405 - val_accuracy: 0.5211\n",
      "Epoch 6/20\n",
      "66/66 [==============================] - 53s 808ms/step - loss: 0.5974 - accuracy: 0.7136 - val_loss: 0.7336 - val_accuracy: 0.5632\n",
      "Epoch 7/20\n",
      "66/66 [==============================] - 55s 837ms/step - loss: 0.5630 - accuracy: 0.7213 - val_loss: 0.8610 - val_accuracy: 0.5517\n",
      "Epoch 8/20\n",
      "66/66 [==============================] - 53s 805ms/step - loss: 0.5309 - accuracy: 0.7371 - val_loss: 0.8664 - val_accuracy: 0.5709\n",
      "Epoch 9/20\n",
      "66/66 [==============================] - 53s 801ms/step - loss: 0.5152 - accuracy: 0.7439 - val_loss: 1.0519 - val_accuracy: 0.5785\n",
      "Epoch 10/20\n",
      "66/66 [==============================] - 56s 844ms/step - loss: 0.5067 - accuracy: 0.7535 - val_loss: 0.6821 - val_accuracy: 0.6169\n",
      "Epoch 11/20\n",
      "51/66 [======================>.......] - ETA: 12s - loss: 0.4801 - accuracy: 0.7714"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(150, 150, 1)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(256, kernel_size=(3, 3), activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    \n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "          epochs=20,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, y_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
